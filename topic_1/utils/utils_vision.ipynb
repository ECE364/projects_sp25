{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6580457",
   "metadata": {},
   "source": [
    "Last updated: 2025-04-07\n",
    "\n",
    "Here are some useful fucntion that can help you judge the accuracy of your model(s). This will be iteratively update. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d6009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IoU (Intersection over Union)\n",
    "def calculate_iou(box1, box2):\n",
    "    # Extract coordinates\n",
    "    x1_min, y1_min, x1_max, y1_max = box1\n",
    "    x2_min, y2_min, x2_max, y2_max = box2\n",
    "    \n",
    "    # Calculate intersection area\n",
    "    x_min = max(x1_min, x2_min)\n",
    "    y_min = max(y1_min, y2_min)\n",
    "    x_max = min(x1_max, x2_max)\n",
    "    y_max = min(y1_max, y2_max)\n",
    "    \n",
    "    if x_max <= x_min or y_max <= y_min:\n",
    "        return 0.0\n",
    "    \n",
    "    intersection = (x_max - x_min) * (y_max - y_min)\n",
    "    \n",
    "    # Calculate union area\n",
    "    area1 = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "    area2 = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "    union = area1 + area2 - intersection\n",
    "    \n",
    "    # Calculate IoU\n",
    "    iou = intersection / union\n",
    "    \n",
    "    return iou\n",
    "\n",
    "# Calculate mAP (mean Average Precision)\n",
    "def calculate_map(results, iou_threshold=0.5):\n",
    "    total_ap = 0.0\n",
    "    total_classes = 0\n",
    "    \n",
    "    # Calculate AP for each class\n",
    "    for class_id in range(1, len(CHINESE_CHARS) + 1):\n",
    "        ap = calculate_ap_for_class(results, class_id, iou_threshold)\n",
    "        if ap is not None:\n",
    "            total_ap += ap\n",
    "            total_classes += 1\n",
    "    \n",
    "    # Calculate mAP\n",
    "    if total_classes > 0:\n",
    "        map_score = total_ap / total_classes\n",
    "        print(f\"mAP@{iou_threshold}: {map_score:.4f}\")\n",
    "        return map_score\n",
    "    else:\n",
    "        print(\"No classes detected for mAP calculation\")\n",
    "        return 0.0\n",
    "\n",
    "# Calculate AP for a specific class\n",
    "def calculate_ap_for_class(results, class_id, iou_threshold):\n",
    "    all_detections = []\n",
    "    all_ground_truths = []\n",
    "    \n",
    "    # Collect all detections and ground truths for this class\n",
    "    for result in results:\n",
    "        # Get detections for this class\n",
    "        class_detections = []\n",
    "        for box, score, label in zip(result['pred_boxes'], result['pred_scores'], result['pred_labels']):\n",
    "            if label == class_id:\n",
    "                class_detections.append({'box': box, 'score': score})\n",
    "        \n",
    "        # Get ground truths for this class\n",
    "        class_ground_truths = []\n",
    "        for box, label in zip(result['gt_boxes'], result['gt_labels']):\n",
    "            if label == class_id:\n",
    "                class_ground_truths.append({'box': box})\n",
    "        \n",
    "        all_detections.append(class_detections)\n",
    "        all_ground_truths.append(class_ground_truths)\n",
    "    \n",
    "    # If no ground truths, skip this class\n",
    "    total_gt = sum(len(gt) for gt in all_ground_truths)\n",
    "    if total_gt == 0:\n",
    "        return None\n",
    "    \n",
    "    # Sort all detections by score\n",
    "    all_detections_flat = []\n",
    "    for img_idx, detections in enumerate(all_detections):\n",
    "        for detection in detections:\n",
    "            all_detections_flat.append({\n",
    "                'img_idx': img_idx,\n",
    "                'box': detection['box'],\n",
    "                'score': detection['score']\n",
    "            })\n",
    "    \n",
    "    all_detections_flat.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    tp = np.zeros(len(all_detections_flat))\n",
    "    fp = np.zeros(len(all_detections_flat))\n",
    "    gt_used = [np.zeros(len(gt)) for gt in all_ground_truths]\n",
    "    \n",
    "    for i, detection in enumerate(all_detections_flat):\n",
    "        img_idx = detection['img_idx']\n",
    "        box = detection['box']\n",
    "        \n",
    "        # Check if detection matches any ground truth\n",
    "        max_iou = -1\n",
    "        max_idx = -1\n",
    "        \n",
    "        for j, gt in enumerate(all_ground_truths[img_idx]):\n",
    "            if gt_used[img_idx][j]:\n",
    "                continue\n",
    "            \n",
    "            iou = calculate_iou(box, gt['box'])\n",
    "            if iou > max_iou:\n",
    "                max_iou = iou\n",
    "                max_idx = j\n",
    "        \n",
    "        # If IoU exceeds threshold, it's a true positive\n",
    "        if max_iou >= iou_threshold and max_idx >= 0:\n",
    "            tp[i] = 1\n",
    "            gt_used[img_idx][max_idx] = 1\n",
    "        else:\n",
    "            fp[i] = 1\n",
    "    \n",
    "    # Calculate cumulative precision and recall\n",
    "    cumsum_tp = np.cumsum(tp)\n",
    "    cumsum_fp = np.cumsum(fp)\n",
    "    recall = cumsum_tp / total_gt\n",
    "    precision = cumsum_tp / (cumsum_tp + cumsum_fp + 1e-10)\n",
    "    \n",
    "    # Calculate AP using 11-point interpolation\n",
    "    ap = 0\n",
    "    for t in np.arange(0, 1.1, 0.1):\n",
    "        if np.sum(recall >= t) == 0:\n",
    "            p = 0\n",
    "        else:\n",
    "            p = np.max(precision[recall >= t])\n",
    "        ap += p / 11\n",
    "    \n",
    "    return ap\n",
    "\n",
    "# Visualize predictions\n",
    "def visualize_predictions(image, gt_boxes, gt_labels, pred_boxes, pred_scores, pred_labels, output_path):\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(1, figsize=(15, 15))\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    # Draw ground truth boxes in green\n",
    "    for box, label in zip(gt_boxes, gt_labels):\n",
    "        x, y, x2, y2 = box\n",
    "        width = x2 - x\n",
    "        height = y2 - y\n",
    "        rect = Rectangle((x, y), width, height, linewidth=2, edgecolor='g', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Add label\n",
    "        char = IDX_TO_CHAR.get(label, \"unknown\")\n",
    "        plt.text(x, y-5, char, color='green', fontsize=12,\n",
    "                bbox=dict(facecolor='white', alpha=0.7))\n",
    "    \n",
    "    # Draw predicted boxes in red\n",
    "    for box, score, label in zip(pred_boxes, pred_scores, pred_labels):\n",
    "        x, y, x2, y2 = box\n",
    "        width = x2 - x\n",
    "        height = y2 - y\n",
    "        rect = Rectangle((x, y), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Add label and score\n",
    "        char = IDX_TO_CHAR.get(label, \"unknown\")\n",
    "        plt.text(x, y2+15, f\"{char} ({score:.2f})\", color='red', fontsize=12,\n",
    "                bbox=dict(facecolor='white', alpha=0.7))\n",
    "    \n",
    "    # Set title\n",
    "    plt.title(f\"Ground Truth (Green) vs Predictions (Red)\")\n",
    "    \n",
    "    # Remove axes\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(output_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Visualization saved to {output_path}\")\n",
    "\n",
    "# Visualize results for a dataset\n",
    "def visualize_results(results, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for result in tqdm(results, desc=\"Visualizing\"):\n",
    "        # Load image\n",
    "        img_path = os.path.join(IMAGE_DIR, result['filename'])\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Visualize\n",
    "        output_path = os.path.join(output_dir, f\"pred_{os.path.splitext(result['filename'])[0]}.png\")\n",
    "        visualize_predictions(\n",
    "            img, \n",
    "            result['gt_boxes'], \n",
    "            result['gt_labels'], \n",
    "            result['pred_boxes'], \n",
    "            result['pred_scores'], \n",
    "            result['pred_labels'], \n",
    "            output_path\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
